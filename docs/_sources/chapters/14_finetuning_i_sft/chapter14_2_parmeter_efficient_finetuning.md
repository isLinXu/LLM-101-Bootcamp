---
file_format: mystnb
kernelspec:
  name: python3
---
# 第14章：监督式微调 I: SFT-14.1 监督式微调基础

## 14.2 参数高效微调技术(PEFT)

随着大型语言模型（LLMs）规模的不断扩大，完整微调这些模型面临着巨大的计算资源挑战。以GPT-3（1750亿参数）或Llama 2（700亿参数）为例，对这些模型进行完整微调需要数百GB的GPU内存和大量计算时间，这对大多数研究者和开发者来说是难以承受的。参数高效微调技术（Parameter-Efficient Fine-Tuning，PEFT）应运而生，它提供了一种在有限资源条件下有效适应大型模型的方法。

### PEFT的概念与必要性

参数高效微调是一系列技术的统称，这些技术的共同目标是在仅更新模型参数的一小部分（通常少于1%）的情况下，实现接近完整微调的性能。PEFT的核心思想是识别并专注于对特定任务最重要的参数子集，而保持大部分预训练参数不变。

PEFT在故事讲述AI开发中的必要性体现在以下几个方面：

1. **资源效率**：
   - 显著减少GPU内存需求，使得在消费级硬件上微调大型模型成为可能
   - 降低计算成本，加快训练速度，缩短开发周期
   - 减少存储需求，因为只需保存少量参数而非完整模型

2. **减轻灾难性遗忘**：
   - 由于大部分预训练参数保持不变，模型更好地保留了预训练阶段获得的知识
   - 这对故事讲述尤为重要，因为它需要平衡特定风格的学习与广泛世界知识的保留

3. **模型共享与部署便利**：
   - 多个任务特定的PEFT模型可以共享同一个基础预训练模型
   - 只需分发和加载小型适配器，而非完整模型，简化了部署流程

4. **迭代开发**：
   - 更快的训练周期使得反复实验和迭代优化变得更加实际
   - 开发者可以尝试不同的数据集、超参数和训练策略，找到最佳配置

### 常见PEFT方法概述

PEFT方法可以根据其修改模型的方式分为几个主要类别：

1. **适配器方法（Adapter Methods）**：
   - **基本原理**：在预训练模型的层之间插入小型可训练模块（适配器），同时冻结原始模型参数
   - **代表技术**：
     - **Adapter**：在Transformer层之后添加包含下投影、激活函数和上投影的小型瓶颈层
     - **AdapterFusion**：允许组合多个预训练的适配器
     - **Compacter**：使用参数化矩阵分解减少适配器参数量
   - **优势**：模块化设计，易于组合不同任务的适配器
   - **局限性**：增加了模型的深度，可能影响推理速度

2. **前缀调优（Prefix Tuning）**：
   - **基本原理**：在输入序列前添加一组可训练的前缀向量，或在每一层添加前缀向量
   - **代表技术**：
     - **Prefix Tuning**：在每一层添加可训练的前缀向量
     - **P-Tuning**：在输入层添加连续的提示向量
     - **P-Tuning v2**：扩展到所有层的前缀调优
   - **优势**：不改变模型架构，适用于各种序列任务
   - **局限性**：前缀长度的选择对性能有显著影响

3. **低秩适应（Low-Rank Adaptation）**：
   - **基本原理**：使用低秩矩阵分解来参数化权重更新
   - **代表技术**：
     - **LoRA**：通过低秩分解矩阵表示权重更新（下一节将详细介绍）
     - **AdaLoRA**：自适应分配不同层的秩
   - **优势**：不增加推理延迟，实现简单，效果显著
   - **局限性**：最优秩的选择需要实验确定

4. **软提示（Soft Prompting）**：
   - **基本原理**：在输入空间中添加或修改可训练的嵌入向量
   - **代表技术**：
     - **Prompt Tuning**：在输入序列前添加可训练的软提示标记
     - **Soft Prompts**：使用连续向量替代离散标记
   - **优势**：概念简单，仅修改输入层
   - **局限性**：表达能力可能受限，通常需要较大的提示长度

5. **选择性参数微调（Selective Parameter Fine-tuning）**：
   - **基本原理**：基于某些标准选择性地微调部分原始模型参数
   - **代表技术**：
     - **BitFit**：仅微调偏置参数
     - **Diff Pruning**：学习稀疏参数更新
   - **优势**：直接修改关键参数，概念简单
   - **局限性**：参数选择策略对性能影响大

### 计算资源与效果的权衡

在选择PEFT方法时，需要考虑计算资源与效果之间的权衡：

1. **参数效率 vs. 性能**：
   - 可训练参数越少，资源需求越低，但可能会限制模型的适应能力
   - 不同任务对参数效率的敏感度不同，故事生成等创造性任务可能需要相对更多的可训练参数

2. **内存效率 vs. 计算效率**：
   - 某些PEFT方法（如适配器）节省内存但可能增加计算量
   - 其他方法（如LoRA）在内存和计算效率之间取得了良好平衡

3. **训练效率 vs. 推理效率**：
   - 一些方法在训练时高效但在推理时引入额外开销
   - 理想的PEFT方法应在不增加推理延迟的情况下实现高效训练

4. **实现复杂性 vs. 灵活性**：
   - 简单的PEFT方法易于实现但可能缺乏灵活性
   - 复杂的方法提供更多调整选项但增加了实现难度

下表比较了几种主要PEFT方法的关键特性：

| 方法 | 可训练参数比例 | 内存效率 | 推理开销 | 实现复杂度 | 适用场景 |
|------|--------------|---------|---------|-----------|---------|
| 完整微调 | 100% | 低 | 无 | 低 | 资源充足，追求最佳性能 |
| Adapter | 0.5-5% | 中 | 有 | 中 | 多任务学习，模块化需求 |
| Prefix Tuning | 0.1-1% | 高 | 轻微 | 中 | NLG任务，如故事生成 |
| LoRA | 0.1-1% | 高 | 可合并消除 | 低 | 通用场景，尤其是生成任务 |
| Prompt Tuning | <0.1% | 极高 | 轻微 | 低 | 简单任务，极限资源约束 |

### PEFT在故事生成中的应用

PEFT技术在故事生成任务中有着独特的应用价值：

1. **风格适应**：
   - 使用PEFT可以快速适应不同的写作风格，如童话、科幻或悬疑
   - 每种风格可以使用单独的小型适配器，共享同一个基础模型
   - 这使得创建"多风格"故事生成系统变得可行

2. **角色定制**：
   - 为不同角色创建专门的PEFT模块，捕捉其独特的语言模式和性格特征
   - 通过组合不同角色的PEFT模块，生成多角色互动的故事

3. **增量能力扩展**：
   - 逐步添加新能力（如诗歌创作、对话生成）而不影响现有能力
   - 每种能力可以使用专门的PEFT模块进行训练

4. **个性化**：
   - 基于用户偏好和反馈，使用极小的PEFT模块进行个性化调整
   - 即使在边缘设备上也能实现个性化，因为PEFT模块非常小

5. **多语言故事**：
   - 使用语言特定的PEFT模块扩展到不同语言的故事生成
   - 保持核心叙事能力不变，只调整语言表达

在实际应用中，LoRA因其简单性和有效性，已成为故事生成任务中最受欢迎的PEFT方法之一。下一节，我们将深入探讨LoRA技术及其在故事讲述AI中的具体应用。