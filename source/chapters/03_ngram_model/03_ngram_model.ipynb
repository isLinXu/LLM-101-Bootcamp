{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter, defaultdict\n",
    "import jieba\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例文本数据\n",
    "sample_text = \"\"\"\n",
    "人工智能是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器。\n",
    "人工智能也可以被定义为使机器能够执行需要人类智能才能完成的任务的计算系统的理论与开发。\n",
    "目前人工智能研究的主要领域包括自然语言处理、机器学习、计算机视觉和专家系统等。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 传统N-gram模型实现\n",
    "def preprocess_text(text, n=3):\n",
    "    \"\"\"对文本进行预处理，分词并生成n-gram序列\"\"\"\n",
    "    tokens = list(jieba.cut(text))\n",
    "    ngrams = []\n",
    "    \n",
    "    # 添加开始和结束标记\n",
    "    tokens = [\"<s>\"] * (n-1) + tokens + [\"</s>\"]\n",
    "    \n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngrams.append(tuple(tokens[i:i+n]))\n",
    "    \n",
    "    return tokens, ngrams\n",
    "\n",
    "def train_ngram_model(text, n=3):\n",
    "    \"\"\"训练传统的n-gram语言模型\"\"\"\n",
    "    tokens, ngrams = preprocess_text(text, n)\n",
    "    \n",
    "    # 计算n-gram和(n-1)-gram的频率\n",
    "    ngram_counts = Counter(ngrams)\n",
    "    context_counts = Counter([gram[:-1] for gram in ngrams])\n",
    "    \n",
    "    # 计算条件概率\n",
    "    model = defaultdict(lambda: defaultdict(float))\n",
    "    for gram in ngram_counts:\n",
    "        context, word = gram[:-1], gram[-1]\n",
    "        model[context][word] = ngram_counts[gram] / context_counts[context]\n",
    "    \n",
    "    return model, tokens\n",
    "\n",
    "def generate_text(model, context, max_length=20):\n",
    "    \"\"\"使用n-gram模型生成文本\"\"\"\n",
    "    result = list(context)\n",
    "    n = len(context) + 1\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        # 获取当前上下文\n",
    "        current_context = tuple(result[-(n-1):])\n",
    "        \n",
    "        # 如果上下文不在模型中，随机选择一个词\n",
    "        if current_context not in model:\n",
    "            break\n",
    "        \n",
    "        # 根据条件概率采样下一个词\n",
    "        next_word_probs = model[current_context]\n",
    "        words = list(next_word_probs.keys())\n",
    "        probs = list(next_word_probs.values())\n",
    "        next_word = random.choices(words, weights=probs)[0]\n",
    "        \n",
    "        # 如果生成结束标记，停止生成\n",
    "        if next_word == \"</s>\":\n",
    "            break\n",
    "        \n",
    "        result.append(next_word)\n",
    "    \n",
    "    return \"\".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试传统N-gram模型\n",
    "def test_traditional_ngram():\n",
    "    print(\"=== 传统N-gram模型测试 ===\")\n",
    "    for n in range(2, 5):\n",
    "        print(f\"\\n--- {n}-gram模型 ---\")\n",
    "        model, tokens = train_ngram_model(sample_text, n)\n",
    "        \n",
    "        # 随机选择一个上下文\n",
    "        start_idx = random.randint(0, len(tokens) - n)\n",
    "        context = tuple(tokens[start_idx:start_idx+n-1])\n",
    "        \n",
    "        print(f\"上下文: {''.join(context)}\")\n",
    "        generated_text = generate_text(model, context)\n",
    "        print(f\"生成文本: {generated_text}\")\n",
    "        \n",
    "        # 计算困惑度 (只是示例，实际应在测试集上计算)\n",
    "        test_tokens, test_ngrams = preprocess_text(sample_text[:len(sample_text)//2], n)\n",
    "        log_prob_sum = 0\n",
    "        count = 0\n",
    "        \n",
    "        for gram in test_ngrams:\n",
    "            context, word = gram[:-1], gram[-1]\n",
    "            if context in model and word in model[context]:\n",
    "                log_prob_sum += np.log(model[context][word])\n",
    "                count += 1\n",
    "        \n",
    "        if count > 0:\n",
    "            perplexity = np.exp(-log_prob_sum / count)\n",
    "            print(f\"困惑度: {perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 基于MLP的N-gram模型\n",
    "class MLPNgramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, context_size):\n",
    "        super(MLPNgramModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, hidden_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.linear2 = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view(inputs.shape[0], -1)\n",
    "        hidden = self.gelu(self.linear1(embeds))\n",
    "        output = self.linear2(hidden)\n",
    "        log_probs = nn.functional.log_softmax(output, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_mlp_ngram(text, n, word_to_ix=None):\n",
    "    \"\"\"准备用于MLP N-gram模型的数据\"\"\"\n",
    "    tokens = list(jieba.cut(text))\n",
    "    tokens = [\"<s>\"] * (n-1) + tokens + [\"</s>\"]\n",
    "    \n",
    "    # 创建词汇表\n",
    "    if word_to_ix is None:\n",
    "        word_to_ix = {word: i for i, word in enumerate(set(tokens))}\n",
    "    \n",
    "    # 生成训练样本\n",
    "    X, y = [], []\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        X.append([word_to_ix[token] for token in tokens[i:i+n-1]])\n",
    "        y.append(word_to_ix[tokens[i+n-1]])\n",
    "    \n",
    "    return torch.tensor(X), torch.tensor(y), word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mlp_ngram():\n",
    "    print(\"\\n=== 基于MLP的N-gram模型测试 ===\")\n",
    "    n = 3  # 使用trigram模型\n",
    "    \n",
    "    # 准备数据\n",
    "    X, y, word_to_ix = prepare_data_for_mlp_ngram(sample_text, n)\n",
    "    ix_to_word = {i: word for word, i in word_to_ix.items()}\n",
    "    vocab_size = len(word_to_ix)\n",
    "    \n",
    "    # 超参数\n",
    "    EMBEDDING_DIM = 50\n",
    "    HIDDEN_DIM = 64\n",
    "    CONTEXT_SIZE = n - 1\n",
    "    LEARNING_RATE = 0.01\n",
    "    EPOCHS = 100\n",
    "    \n",
    "    # 创建模型\n",
    "    model = MLPNgramModel(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, CONTEXT_SIZE)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # 训练循环\n",
    "    print(\"开始训练...\")\n",
    "    losses = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.zero_grad()\n",
    "        log_probs = model(X)\n",
    "        loss = loss_function(log_probs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # 绘制损失曲线\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, EPOCHS+1), losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('mlp_ngram_loss.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 评估模型\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        log_probs = model(X)\n",
    "        _, predicted = log_probs.max(1)\n",
    "        total = y.size(0)\n",
    "        correct = predicted.eq(y).sum().item()\n",
    "        accuracy = 100. * correct / total\n",
    "        \n",
    "        # 计算困惑度\n",
    "        test_loss = loss_function(log_probs, y).item()\n",
    "        perplexity = np.exp(test_loss)\n",
    "        \n",
    "        print(f\"准确率: {accuracy:.2f}%\")\n",
    "        print(f\"困惑度: {perplexity:.4f}\")\n",
    "    \n",
    "    # 生成一些文本\n",
    "    print(\"\\n生成文本示例:\")\n",
    "    for _ in range(3):\n",
    "        # 随机选择一个上下文\n",
    "        start_idx = random.randint(0, len(X) - 1)\n",
    "        context = X[start_idx].tolist()\n",
    "        \n",
    "        # 生成文本\n",
    "        result = [ix_to_word[idx] for idx in context]\n",
    "        for _ in range(15):\n",
    "            with torch.no_grad():\n",
    "                input_tensor = torch.tensor([context])\n",
    "                log_probs = model(input_tensor)\n",
    "                _, next_word_idx = log_probs.max(1)\n",
    "                next_word = ix_to_word[next_word_idx.item()]\n",
    "                \n",
    "                if next_word == \"</s>\":\n",
    "                    break\n",
    "                    \n",
    "                result.append(next_word)\n",
    "                context = context[1:] + [next_word_idx.item()]\n",
    "        \n",
    "        print(\"\".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 激活函数比较\n",
    "def plot_activation_functions():\n",
    "    print(\"\\n=== 激活函数比较 ===\")\n",
    "    x = np.linspace(-5, 5, 1000)\n",
    "    \n",
    "    # Sigmoid\n",
    "    sigmoid = 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    # Tanh\n",
    "    tanh = np.tanh(x)\n",
    "    \n",
    "    # ReLU\n",
    "    relu = np.maximum(0, x)\n",
    "    \n",
    "    # Leaky ReLU\n",
    "    leaky_relu = np.where(x > 0, x, 0.01 * x)\n",
    "    \n",
    "    # ELU\n",
    "    elu = np.where(x > 0, x, 1.0 * (np.exp(x) - 1))\n",
    "    \n",
    "    # GELU (近似)\n",
    "    gelu = 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))\n",
    "    \n",
    "    # 绘图\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.plot(x, sigmoid)\n",
    "    plt.grid(True)\n",
    "    plt.title('Sigmoid')\n",
    "    \n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.plot(x, tanh)\n",
    "    plt.grid(True)\n",
    "    plt.title('Tanh')\n",
    "    \n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.plot(x, relu)\n",
    "    plt.grid(True)\n",
    "    plt.title('ReLU')\n",
    "    \n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.plot(x, leaky_relu)\n",
    "    plt.grid(True)\n",
    "    plt.title('Leaky ReLU')\n",
    "    \n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.plot(x, elu)\n",
    "    plt.grid(True)\n",
    "    plt.title('ELU')\n",
    "    \n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.plot(x, gelu)\n",
    "    plt.grid(True)\n",
    "    plt.title('GELU')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('activation_functions.png')\n",
    "    plt.close()\n",
    "    print(\"已生成激活函数对比图: activation_functions.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 传统N-gram模型测试 ===\n",
      "\n",
      "--- 2-gram模型 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache /var/folders/7c/wh8mv84j2qg0hpjr19htwzq00000gn/T/jieba.cache\n",
      "Loading model cost 0.564 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上下文: 机器\n",
      "生成文本: 机器学习、机器学习、机器学习、计算机视觉和专家系统等。\n",
      "人工智能是计算机科学的理论\n",
      "困惑度: 1.6777\n",
      "\n",
      "--- 3-gram模型 ---\n",
      "上下文: 。\n",
      "\n",
      "生成文本: 。\n",
      "目前人工智能研究的主要领域包括自然语言处理、机器学习、计算机视觉和专家系统等。\n",
      "\n",
      "困惑度: 1.0806\n",
      "\n",
      "--- 4-gram模型 ---\n",
      "上下文: ，并生产\n",
      "生成文本: ，并生产出一种新的能以人类智能相似的方式做出反应的智能机器。\n",
      "人工智能也\n",
      "困惑度: 1.0000\n",
      "\n",
      "=== 激活函数比较 ===\n",
      "已生成激活函数对比图: activation_functions.png\n",
      "\n",
      "=== 基于MLP的N-gram模型测试 ===\n",
      "开始训练...\n",
      "Epoch 10, Loss: 0.5335\n",
      "Epoch 20, Loss: 0.0810\n",
      "Epoch 30, Loss: 0.0755\n",
      "Epoch 40, Loss: 0.0745\n",
      "Epoch 50, Loss: 0.0741\n",
      "Epoch 60, Loss: 0.0741\n",
      "Epoch 70, Loss: 0.0740\n",
      "Epoch 80, Loss: 0.0740\n",
      "Epoch 90, Loss: 0.0740\n",
      "Epoch 100, Loss: 0.0740\n",
      "准确率: 95.12%\n",
      "困惑度: 1.0768\n",
      "\n",
      "生成文本示例:\n",
      "智能才能完成的任务的计算系统的理论与开发。\n",
      "\n",
      "领域包括自然语言处理、机器学习、计算机视觉和专家系统等。\n",
      "\n",
      "人类智能才能完成的任务的计算系统的理论与开发。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_traditional_ngram()\n",
    "    plot_activation_functions()\n",
    "    test_mlp_ngram() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
